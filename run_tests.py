#!/usr/bin/env python3
"""
Sistema de pruebas automatizado para el compilador Lizard
Ejecuta todos los archivos de prueba (.rwlz) y muestra los resultados usando Rich
"""

import os
import sys
import re
import traceback
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from io import StringIO
import contextlib

# Importar Rich para formateo de salida
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
from rich.layout import Layout
from rich.text import Text
from rich.live import Live
from rich import box

# Importar componentes del compilador
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
from Lexer.lexer import LizardLexer
from Parser.parser import LizardParser
from Utils.errors import reset_errors, get_error_count

console = Console()

class TestResult:
    """Representa el resultado de una prueba individual"""
    def __init__(self, filename: str, expected_type: str, expected_description: str = ""):
        self.filename = filename
        self.expected_type = expected_type  # "VALID" o "ERROR"
        self.expected_description = expected_description
        self.actual_result = None  # "SUCCESS", "ERROR", "EXCEPTION"
        self.error_message = ""
        self.error_type = ""  # "LEXER", "PARSER", "EXCEPTION"
        self.ast_generated = False
        self.exception_details = ""

    @property
    def passed(self) -> bool:
        """Determina si la prueba pas√≥ seg√∫n el resultado esperado"""
        if self.expected_type == "VALID":
            return self.actual_result == "SUCCESS"
        elif self.expected_type == "ERROR":
            return self.actual_result in ["ERROR", "EXCEPTION"]
        return False

    @property
    def status_emoji(self) -> str:
        """Devuelve un emoji representando el estado de la prueba"""
        if self.passed:
            return "‚úÖ"
        else:
            return "‚ùå"

    @property
    def status_color(self) -> str:
        """Devuelve el color para mostrar el resultado"""
        if self.passed:
            return "green"
        else:
            return "red"

class TestRunner:
    """Ejecutor de pruebas principal"""
    
    def __init__(self, test_dir: str = "Test"):
        self.test_dir = Path(test_dir)
        self.valid_tests_dir = self.test_dir / "valid_tests"
        self.invalid_tests_dir = self.test_dir / "invalid_tests"
        self.results: List[TestResult] = []
        
    def extract_test_info(self, file_path: Path) -> Tuple[str, str]:
        """Extrae informaci√≥n del TEST o ERROR de los comentarios del archivo"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Buscar comentarios TEST: o ERROR:
            test_match = re.search(r'//\s*TEST:\s*(.+)', content, re.IGNORECASE)
            error_match = re.search(r'//\s*ERROR:\s*(.+)', content, re.IGNORECASE)
            
            if test_match:
                return "VALID", test_match.group(1).strip()
            elif error_match:
                return "ERROR", error_match.group(1).strip()
            else:
                # Inferir del nombre del directorio
                if "valid" in str(file_path):
                    return "VALID", "Prueba v√°lida sin descripci√≥n espec√≠fica"
                else:
                    return "ERROR", "Prueba inv√°lida sin descripci√≥n espec√≠fica"
                    
        except Exception as e:
            console.print(f"[yellow]Advertencia: No se pudo leer {file_path}: {e}[/yellow]")
            return "UNKNOWN", str(e)

    def capture_compiler_output(self):
        """Captura la salida del compilador (stdout y stderr)"""
        return StringIO(), StringIO()
    
    def run_single_test(self, file_path: Path) -> TestResult:
        """Ejecuta una prueba individual"""
        expected_type, description = self.extract_test_info(file_path)
        result = TestResult(file_path.name, expected_type, description)
        
        # Capturar salida de errores
        captured_output = StringIO()
        captured_errors = StringIO()
        
        try:
            # Leer el archivo fuente
            with open(file_path, 'r', encoding='utf-8') as f:
                source = f.read()
            
            # Reiniciar contador de errores
            reset_errors()
            
            # Capturar salida de errores para obtener mensajes espec√≠ficos
            with contextlib.redirect_stdout(captured_output), contextlib.redirect_stderr(captured_errors):
                # Fase 1: An√°lisis l√©xico
                lexer = LizardLexer()
                try:
                    tokens = list(lexer.tokenize(source))
                except Exception as lex_error:
                    result.actual_result = "ERROR"
                    result.error_type = "LEXER"
                    result.error_message = f"Error l√©xico: {str(lex_error)}"
                    return result
                
                # Verificar errores del lexer
                lexer_errors = captured_errors.getvalue()
                if get_error_count() > 0 or lexer_errors:
                    result.actual_result = "ERROR"
                    result.error_type = "LEXER"
                    if lexer_errors:
                        # Extraer mensaje espec√≠fico del error l√©xico
                        error_lines = lexer_errors.strip().split('\n')
                        specific_error = error_lines[-1] if error_lines else "Error l√©xico no especificado"
                        result.error_message = f"Error l√©xico: {specific_error}"
                    else:
                        result.error_message = f"Error l√©xico detectado ({get_error_count()} errores)"
                    return result
                
                # Fase 2: An√°lisis sint√°ctico
                parser = LizardParser()
                reset_errors()  # Reiniciar para el parser
                captured_errors.truncate(0)  # Limpiar buffer de errores
                captured_errors.seek(0)
                
                try:
                    ast = parser.parse(lexer.tokenize(source))
                except Exception as parse_error:
                    result.actual_result = "ERROR"
                    result.error_type = "PARSER"
                    result.error_message = f"Error sint√°ctico: {str(parse_error)}"
                    return result
                
                # Verificar resultado del parsing
                parser_errors = captured_errors.getvalue()
                if ast is None or get_error_count() > 0 or parser_errors:
                    result.actual_result = "ERROR"
                    result.error_type = "PARSER"
                    if parser_errors:
                        # Extraer mensaje espec√≠fico del error sint√°ctico
                        error_lines = parser_errors.strip().split('\n')
                        # Buscar l√≠neas que contengan informaci√≥n de error √∫til
                        specific_errors = []
                        for line in error_lines:
                            if 'syntax error' in line.lower() or 'parse error' in line.lower():
                                specific_errors.append(line.strip())
                        
                        if specific_errors:
                            result.error_message = f"Error sint√°ctico: {specific_errors[-1]}"
                        else:
                            result.error_message = "Error sint√°ctico: estructura inv√°lida"
                    else:
                        result.error_message = f"Error sint√°ctico detectado ({get_error_count()} errores)"
                else:
                    result.actual_result = "SUCCESS"
                    result.ast_generated = True
                    result.error_message = "Compilaci√≥n exitosa"
                
        except Exception as e:
            result.actual_result = "EXCEPTION"
            result.error_type = "EXCEPTION"
            result.error_message = f"Excepci√≥n: {str(e)}"
            result.exception_details = traceback.format_exc()
            
        return result

    def collect_test_files(self) -> List[Path]:
        """Recolecta todos los archivos de prueba .rwlz"""
        test_files = []
        
        # Archivos v√°lidos
        if self.valid_tests_dir.exists():
            test_files.extend(self.valid_tests_dir.glob("*.rwlz"))
            
        # Archivos inv√°lidos
        if self.invalid_tests_dir.exists():
            test_files.extend(self.invalid_tests_dir.glob("*.rwlz"))
            
        return sorted(test_files)

    def run_all_tests(self) -> None:
        """Ejecuta todas las pruebas con barra de progreso"""
        test_files = self.collect_test_files()
        
        if not test_files:
            console.print("[red]‚ùå No se encontraron archivos de prueba (.rwlz)[/red]")
            return
            
        console.print(f"[cyan]üîç Encontrados {len(test_files)} archivos de prueba[/cyan]")
        console.print()
        
        # Ejecutar pruebas con barra de progreso
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            console=console
        ) as progress:
            
            task = progress.add_task("[green]Ejecutando pruebas...", total=len(test_files))
            
            for test_file in test_files:
                progress.update(task, description=f"[green]Probando {test_file.name}...")
                result = self.run_single_test(test_file)
                self.results.append(result)
                progress.advance(task)

    def generate_summary_table(self) -> Table:
        """Genera tabla de resumen de resultados"""
        table = Table(title="üìä Resumen de Pruebas", box=box.ROUNDED)
        table.add_column("M√©trica", style="cyan", width=20)
        table.add_column("Valor", style="white", width=15)
        table.add_column("Detalle", style="dim", width=40)
        
        total_tests = len(self.results)
        passed_tests = sum(1 for r in self.results if r.passed)
        failed_tests = total_tests - passed_tests
        
        valid_tests = [r for r in self.results if r.expected_type == "VALID"]
        invalid_tests = [r for r in self.results if r.expected_type == "ERROR"]
        
        valid_passed = sum(1 for r in valid_tests if r.passed)
        invalid_passed = sum(1 for r in invalid_tests if r.passed)
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        table.add_row("Total de Pruebas", str(total_tests), f"Archivos .rwlz procesados")
        table.add_row("‚úÖ Pasaron", f"[green]{passed_tests}[/green]", f"Comportamiento esperado")
        table.add_row("‚ùå Fallaron", f"[red]{failed_tests}[/red]", f"Comportamiento inesperado")
        table.add_row("üìä Tasa de √âxito", f"[{'green' if success_rate >= 80 else 'yellow' if success_rate >= 60 else 'red'}]{success_rate:.1f}%[/]", "Porcentaje de pruebas exitosas")
        table.add_row("", "", "")
        table.add_row("üü¢ Pruebas V√°lidas", f"{len(valid_tests)}", f"‚úÖ {valid_passed} / ‚ùå {len(valid_tests) - valid_passed}")
        table.add_row("üî¥ Pruebas Inv√°lidas", f"{len(invalid_tests)}", f"‚úÖ {invalid_passed} / ‚ùå {len(invalid_tests) - invalid_passed}")
        
        return table

    def generate_detailed_table(self, test_type: str) -> Table:
        """Genera tabla detallada para un tipo espec√≠fico de pruebas"""
        if test_type == "VALID":
            filtered_results = [r for r in self.results if r.expected_type == "VALID"]
            title = "üü¢ Pruebas V√°lidas - Resultados Detallados"
            expected_col = "Funcionalidad Esperada"
        else:
            filtered_results = [r for r in self.results if r.expected_type == "ERROR"]
            title = "üî¥ Pruebas Inv√°lidas - Resultados Detallados"
            expected_col = "Error Esperado"
            
        table = Table(title=title, box=box.ROUNDED)
        table.add_column("Estado", justify="center", width=6)
        table.add_column("Archivo", style="cyan", width=18)
        table.add_column(expected_col, style="dim", width=45)
        table.add_column("Resultado", width=30)
        
        for result in sorted(filtered_results, key=lambda x: (not x.passed, x.filename)):
            status = result.status_emoji
            filename = result.filename
            expected = result.expected_description[:32] + "..." if len(result.expected_description) > 35 else result.expected_description
            
            # Formatear resultado actual con tipo de error
            if result.actual_result == "SUCCESS":
                actual = f"[green]‚úì Compilado exitosamente[/green]"
            elif result.actual_result == "ERROR":
                if result.error_type == "LEXER":
                    actual = f"[yellow]‚ö† Error L√©xico[/yellow]"
                elif result.error_type == "PARSER":
                    actual = f"[orange3]‚ö† Error Sint√°ctico[/orange3]"
                else:
                    actual = f"[yellow]‚ö† Error Detectado[/yellow]"
            elif result.actual_result == "EXCEPTION":
                actual = f"[red]üí• Excepci√≥n del Sistema[/red]"
            else:
                actual = f"[dim]? Estado Desconocido[/dim]"
            
            # Color de fila seg√∫n el resultado
            if result.passed:
                table.add_row(status, filename, expected, actual)
            else:
                table.add_row(status, f"[red]{filename}[/red]", expected, actual)
        
        return table

    def generate_error_details_table(self) -> Optional[Table]:
        """Genera tabla con detalles de errores para pruebas fallidas"""
        failed_tests = [r for r in self.results if not r.passed]
        
        if not failed_tests:
            return None
            
        table = Table(title="üîç Detalles de Pruebas Fallidas", box=box.ROUNDED)
        table.add_column("Archivo", style="red", width=18)
        table.add_column("Esperado", style="cyan", width=12)
        table.add_column("Obtenido", style="yellow", width=15)
        table.add_column("Tipo Error", style="magenta", width=12)
        table.add_column("Descripci√≥n del Error", style="dim", width=45)
        
        for result in failed_tests:
            expected = "‚úì √âxito" if result.expected_type == "VALID" else "‚ùå Error"
            
            if result.actual_result == "SUCCESS":
                obtained = "‚úì √âxito"
            elif result.actual_result == "ERROR":
                obtained = "‚ùå Error"
            elif result.actual_result == "EXCEPTION":
                obtained = "üí• Excepci√≥n"
            else:
                obtained = "? Desconocido"
            
            error_type = result.error_type if result.error_type else "N/A"
            error_msg = result.error_message[:42] + "..." if len(result.error_message) > 45 else result.error_message
            
            table.add_row(result.filename, expected, obtained, error_type, error_msg)
        
        return table

    def print_results(self) -> None:
        """Imprime todos los resultados formateados"""
        console.clear()
        
        # T√≠tulo principal
        title_text = Text("ü¶é LIZARD COMPILER - SISTEMA DE PRUEBAS", style="bold magenta")
        console.print(Panel(title_text, box=box.DOUBLE, padding=(1, 2)))
        console.print()
        
        # Resumen general
        console.print(self.generate_summary_table())
        console.print()
        
        # Tablas detalladas
        console.print(self.generate_detailed_table("VALID"))
        console.print()
        
        console.print(self.generate_detailed_table("ERROR"))
        console.print()
        
        # Detalles de errores si existen
        error_table = self.generate_error_details_table()
        if error_table:
            console.print(error_table)
            console.print()
        
        # Mensaje final
        total_tests = len(self.results)
        passed_tests = sum(1 for r in self.results if r.passed)
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        if success_rate == 100:
            final_msg = Text("üéâ ¬°TODAS LAS PRUEBAS PASARON! üéâ", style="bold green")
        elif success_rate >= 80:
            final_msg = Text(f"‚ú® {success_rate:.1f}% de pruebas exitosas - ¬°Buen trabajo!", style="bold yellow")
        else:
            final_msg = Text(f"‚ö†Ô∏è {success_rate:.1f}% de pruebas exitosas - Necesita atenci√≥n", style="bold red")
            
        console.print(Panel(final_msg, box=box.ROUNDED, padding=(1, 2)))

def main():
    """Funci√≥n principal"""
    # Cambiar al directorio del script si no estamos all√≠
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    
    # Verificar que estamos en el directorio correcto
    if not os.path.exists("Test"):
        console.print("[red]‚ùå Error: No se encontr√≥ el directorio 'Test'[/red]")
        console.print("[dim]Aseg√∫rate de que el directorio Test existe en la ra√≠z del proyecto[/dim]")
        sys.exit(1)
    
    # Crear y ejecutar runner de pruebas
    runner = TestRunner()
    
    try:
        console.print("[bold cyan]ü¶é Sistema de Pruebas del Compilador Lizard[/bold cyan]")
        console.print()
        
        runner.run_all_tests()
        runner.print_results()
        
    except KeyboardInterrupt:
        console.print("\n[yellow]‚ö†Ô∏è Pruebas interrumpidas por el usuario[/yellow]")
        sys.exit(1)
    except Exception as e:
        console.print(f"[red]‚ùå Error inesperado: {e}[/red]")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
